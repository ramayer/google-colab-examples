{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNc/A46FdG7Gu/+lKiOzd0v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramayer/google-colab-examples/blob/main/Einx_vs_torch_einsum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison of Einx vs raw Pytorch for multi-head self attention\n",
        "\n",
        "\n",
        "| Dimension/Feature         | MultiHeadAttention_einx (einx)         | MultiHeadAttention_torch (PyTorch)         |\n",
        "|--------------------------|-----------------------------------------|--------------------------------------------|\n",
        "| Batch                    | Implicit via \"...\" (no manual handling) | Explicit, must reshape/permute manually    |\n",
        "| Channel                  | Named as \"C\" or part of \"...\"           | Explicit index, must track position        |\n",
        "| Number of Heads          | Named as \"nh\" in pattern string         | Explicit index (e.g., index 2 after permute/view) |\n",
        "| Head Dimension           | Named as \"dh\" in pattern string         | Explicit index (e.g., index 4 after permute/view) |\n",
        "| Sequence/Spatial (N/H/W) | Named as \"H\", \"W\", \"N\" in pattern       | Explicit index, must compute/track         |\n",
        "| Rearrangement            | Declarative: einx.rearrange pattern     | Imperative: view/permute with indices      |\n",
        "| Contraction (dot prod)   | Declarative: einx.dot pattern           | Imperative: torch.bmm, must match dims     |\n",
        "| Softmax                  | Declarative: einx.softmax pattern       | Explicit: F.softmax(dim=...)               |\n",
        "| Adding new dims/layouts  | Easy: update pattern string             | Manual: update all view/permute indices    |\n",
        "| Readability              | High: dimension names, \"...\" for batch  | Lower: must track indices, verbose         |\n"
      ],
      "metadata": {
        "id": "mCLgMVgaU-m9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einx\n",
        "import einx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvkHkNqXVLmC",
        "outputId": "37a474af-fa10-4494-9ccc-d2e2b4123033"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einx\n",
            "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from einx) (2.0.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from einx) (1.14.0)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from einx) (2.4.7)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->einx) (1.3.0)\n",
            "Downloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einx\n",
            "Successfully installed einx-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1EUC9umAV7Kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention_torch(nn.Module):\n",
        "    \"\"\"Multi-head self-attention using torch.bmm (no einsum).\"\"\"\n",
        "    def __init__(self, channels, num_heads=8):\n",
        "        super().__init__()\n",
        "        assert channels % num_heads == 0\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = channels // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "        self.qkv = nn.Conv2d(channels, channels * 3, kernel_size=1)\n",
        "        self.proj = nn.Conv2d(channels, channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        N = H * W\n",
        "        qkv = self.qkv(x)  # (B, 3*C, H, W)\n",
        "\n",
        "        # reshape to (3, B, heads, N, head_dim)\n",
        "        qkv = qkv.view(B, 3, self.num_heads, self.head_dim, N)\n",
        "        qkv = qkv.permute(1, 0, 2, 4, 3).contiguous()  # (3, B, heads, N, head_dim)\n",
        "\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]  # each: (B, heads, N, head_dim)\n",
        "\n",
        "        # merge batch and heads for batched matrix-multiply with bmm\n",
        "        bh = B * self.num_heads\n",
        "        q = q.view(bh, N, self.head_dim)   # (B*heads, N, head_dim)\n",
        "        k = k.view(bh, N, self.head_dim)   # (B*heads, N, head_dim)\n",
        "        v = v.view(bh, N, self.head_dim)   # (B*heads, N, head_dim)\n",
        "\n",
        "        # compute attention scores via bmm: (B*heads, N, N)\n",
        "        scores = torch.bmm(q, k.transpose(1, 2)) * self.scale\n",
        "        attn = F.softmax(scores, dim=-1)\n",
        "\n",
        "        # weighted sum: (B*heads, N, head_dim)\n",
        "        out = torch.bmm(attn, v)\n",
        "\n",
        "        # restore shape to (B, C, H, W)\n",
        "        out = out.view(B, self.num_heads, N, self.head_dim)           # (B, heads, N, head_dim)\n",
        "        out = out.permute(0, 1, 3, 2).contiguous().view(B, self.num_heads * self.head_dim, H, W)\n",
        "        return self.proj(out)"
      ],
      "metadata": {
        "id": "QrQwnAybVKNw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention_einx(nn.Module):\n",
        "    def __init__(self, channels, num_heads=8):\n",
        "        super().__init__()\n",
        "        assert channels % num_heads == 0\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = channels // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "        self.qkv = nn.Conv2d(channels, channels * 3, kernel_size=1)\n",
        "        self.proj = nn.Conv2d(channels, channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = einx.rearrange('... (qkv nh dh) H W -> qkv ... nh (H W) dh',\n",
        "                        qkv, qkv=3, nh=self.num_heads, dh=self.head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        attn = einx.dot('... N dh, ... M dh -> ... N M', q, k) * self.scale\n",
        "        attn = einx.softmax('... N [M]', attn)\n",
        "        out = einx.dot('... N M, ... M d -> ... N d', attn, v)\n",
        "        out = einx.rearrange('... nh (H W) dh -> ... (nh dh) H W',\n",
        "                        out,  nh=self.num_heads, dh=self.head_dim, H=H, W=W)\n",
        "        return self.proj(out)"
      ],
      "metadata": {
        "id": "S2vNXyCdVjzx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"\n",
        "Notice the differences in the models above.\n",
        "\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "A-XGMzsKWBrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate one model, copy its state to the other, and verify identical forwards\n",
        "torch.manual_seed(0)\n",
        "channels, num_heads = 16, 4\n",
        "B, H, W = 2, 8, 8\n",
        "\n",
        "m1 = MultiHeadAttention_torch(channels, num_heads=num_heads)\n",
        "m2 = MultiHeadAttention_einx(channels, num_heads=num_heads)\n",
        "\n",
        "# copy parameters\n",
        "m2.load_state_dict(m1.state_dict())\n",
        "\n",
        "m1.eval(); m2.eval()\n",
        "\n",
        "torch.manual_seed(1)\n",
        "x = torch.randn(B, channels, H, W)\n",
        "\n",
        "out1 = m1(x)\n",
        "out2 = m2(x)\n",
        "\n",
        "max_diff = (out1 - out2).abs().max().item()\n",
        "print(\"max_abs_diff:\", max_diff)\n",
        "assert torch.allclose(out1, out2, atol=1e-6, rtol=1e-5), \"Forward outputs differ\"\n",
        "print(\"Verification passed: forward outputs are identical within tolerance.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFDLNITLVkZC",
        "outputId": "f2ee18d0-cc9d-4e6e-a4a6-754756b22b3e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_abs_diff: 0.0\n",
            "Verification passed: forward outputs are identical within tolerance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "import torch\n",
        "\n",
        "\n",
        "class TestMultiHeadAttention(unittest.TestCase):\n",
        "    def test_output_shape(self):\n",
        "        # channels must be divisible by num_heads\n",
        "        channels, num_heads = 16, 4\n",
        "        B, H, W = 2, 8, 8\n",
        "        model = MultiHeadAttention_einx(channels, num_heads=num_heads)\n",
        "        x = torch.randn(B, channels, H, W)\n",
        "        out = model(x)\n",
        "        self.assertEqual(out.shape, x.shape)\n",
        "\n",
        "    def test_backward_computes_gradients(self):\n",
        "        channels, num_heads = 12, 3\n",
        "        B, H, W = 2, 6, 6\n",
        "        model = MultiHeadAttention_einx(channels, num_heads=num_heads)\n",
        "        x = torch.randn(B, channels, H, W, requires_grad=True)\n",
        "        out = model(x)\n",
        "        loss = out.sum()\n",
        "        loss.backward()\n",
        "        # At least one parameter should have a non-zero gradient\n",
        "        grads = [p.grad for p in model.parameters()]\n",
        "        self.assertTrue(any(g is not None and g.abs().sum().item() > 0 for g in grads))\n",
        "\n",
        "    def test_deterministic_forward_given_same_inputs(self):\n",
        "        torch.manual_seed(0)\n",
        "        channels, num_heads = 8, 2\n",
        "        B, H, W = 1, 4, 4\n",
        "        model = MultiHeadAttention_einx(channels, num_heads=num_heads)\n",
        "        x = torch.randn(B, channels, H, W)\n",
        "        out1 = model(x)\n",
        "        out2 = model(x)\n",
        "        self.assertTrue(torch.allclose(out1, out2))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # In a Jupyter environment, avoid exiting the kernel\n",
        "    unittest.main(argv=[\"\"], exit=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh77gA24W-mp",
        "outputId": "61a9f340-9d0c-43ee-9b87-1eb8b44ef14c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "...\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 0.664s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TbtDCnL0W_Ao"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}