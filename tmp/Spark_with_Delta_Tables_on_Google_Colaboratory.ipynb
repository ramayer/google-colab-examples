{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ramayer/google-colab-examples/blob/main/tmp/Spark_with_Delta_Tables_on_Google_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvD4HBMi0ohY"
   },
   "source": [
    "# Install Spark with Delta Table Support\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuHlNwQRGwQ_"
   },
   "source": [
    "#### Install Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUhBhrGmyAvs"
   },
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaplmdWPO02r"
   },
   "source": [
    "#### install Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XF-e1DAsGUaL",
    "outputId": "979c42d4-05b3-4fd5-af16-f224dd558bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.1.1-bin-had 100%[===================>] 218.13M  2.10MB/s    in 2m 2s   \n"
     ]
    }
   ],
   "source": [
    "!(wget -q --show-progress -nc https://mirrors.ocf.berkeley.edu/apache/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz)\n",
    "!tar xf spark-3.1.1-bin-hadoop3.2.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4Kjvk_h1AHl"
   },
   "source": [
    "# Set Environment Variables\n",
    "Set the locations where Spark and Java are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Xnb_ePUyQIL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2hVj29_H4NC",
    "outputId": "f288b764-0c6d-4c8b-f51a-725c0347819c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
      "\u001b[K     |████████████████████████████████| 212.3MB 67kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 15.8MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=d2f2602e7e8e6f5ddb59f9cd4521d961cdaba776f177176644b3453a7dc11178\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9 pyspark-3.1.1\n",
      "  Building wheel for delta (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pyspark\n",
    "!pip install -q findspark\n",
    "!pip install -q delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwU28K5f1H3P"
   },
   "source": [
    "# Start a SparkSession\n",
    "This will start a local Spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "zgReRGl0y23D",
    "outputId": "97fb3db6-8117-4e21-e435-fe3e0d6c01e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://d63c45005bb1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MyApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff5437e02d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "import pyspark\n",
    "\n",
    "MAX_MEMORY=\"8g\"\n",
    "findspark.init()\n",
    "#findspark.init(\"/content/spark-3.0.0-preview2-bin-hadoop3.2\")# SPARK_HOME\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "\n",
    "spark = (pyspark.sql.SparkSession.builder.appName(\"MyApp\") \n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:0.8.0\") \n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \n",
    "    .config(\"spark.executor.memory\", MAX_MEMORY) \n",
    "    .config(\"spark.driver.memory\", MAX_MEMORY) \n",
    "    .enableHiveSupport() \n",
    "    .getOrCreate()        \n",
    "    )\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwAYlV_pJV0Z"
   },
   "outputs": [],
   "source": [
    "\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XyLUSLvHJOoI"
   },
   "outputs": [],
   "source": [
    "import delta\n",
    "df = spark.createDataFrame([{'hi':'hello','w':'world'}])\n",
    "\n",
    "df.write.format('delta').mode('overwrite').option(\"mergeSchema\", \"true\").save('/tmp/delta1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReDg1_zYMsT5",
    "outputId": "b4666341-f60a-4b82-b9e8-115d28fe697f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         108G   40G   69G  37% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
      "shm             5.9G     0  5.9G   0% /dev/shm\n",
      "tmpfs           6.4G   36K  6.4G   1% /var/colab\n",
      "/dev/sda1       114G   42G   73G  37% /etc/hosts\n",
      "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
      "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
      "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3ULPx4Y1LiR"
   },
   "source": [
    "# Use Spark!\n",
    "That's all there is to it - you're ready to use Spark!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XJp8ZI-VzYEz",
    "outputId": "61987dab-a0f7-4199-f467-24ada011cb21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|hello|\n",
      "+-----+\n",
      "|world|\n",
      "|world|\n",
      "|world|\n",
      "+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZkw_gPEQvId",
    "outputId": "4935d748-1059-46df-d377-63300055eb00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hello='world'), Row(hello='world'), Row(hello='world')]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifLjuy1_Wf_e"
   },
   "outputs": [],
   "source": [
    "file_loc = './sample_data/california_housing_train.csv'\n",
    "df_spark = spark.read.csv(file_loc, inferSchema=True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ew4Ew9gEXQ2a",
    "outputId": "bde3d826-cb4d-4a6c-b221-a53cfc3b4c99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: solr: command not found\n"
     ]
    }
   ],
   "source": [
    "!solr -c"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Spark with Delta Tables on Google Colaboratory.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
