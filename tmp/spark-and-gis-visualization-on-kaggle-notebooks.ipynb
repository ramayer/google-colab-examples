{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ramayer/google-colab-examples/blob/main/tmp/spark-and-gis-visualization-on-kaggle-notebooks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark with GIS visualization In Kaggle Notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_packages = {\"keplergl\",\"geopandas\",\"h3\",\"geocoder\"}\n",
    "\n",
    "import pkg_resources\n",
    "for lib in required_packages - {pkg.key for pkg in pkg_resources.working_set}:\n",
    "  print(f\"installing {lib}\")\n",
    "  %pip install -q --upgrade pip\n",
    "  %pip install --use-feature=2020-resolver -q $lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh -c ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "MAX_MEMORY = \"8g\"  # 24 gives OOM here.\n",
    "\n",
    "spark = (pyspark.sql.SparkSession.builder.appName(\"MyApp\") \n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:0.8.0\") \n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \n",
    "    .config(\"spark.executor.memory\", MAX_MEMORY) \n",
    "    .config(\"spark.driver.memory\", MAX_MEMORY) \n",
    "    .enableHiveSupport() \n",
    "    .getOrCreate()        \n",
    "    )\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([{'hi':'hello','w':'world'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df.write.format('delta').mode('overwrite').option(\"mergeSchema\", \"true\").save('/tmp/delta1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('delta').load('/tmp/delta1')\n",
    "df.createOrReplaceTempView('d1')\n",
    "spark.sql('select * from d1').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keplergl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_1 = keplergl.KeplerGl(height=600)\n",
    "map_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_for_databricks = '''\n",
    "  <script>\n",
    "    var targetHeight = \"{self.height or 600}px\";\n",
    "    window.setInterval(function() {{\n",
    "      if (document.body && document.body.style && document.body.style.height !== targetHeight) {{\n",
    "        document.body.style.height = targetHeight;\n",
    "      }}\n",
    "    }}, 2500)\n",
    "    </script>\n",
    "    '''\n",
    "orig_html   = keplergl.KeplerGl._repr_html_(map_1)\n",
    "better_html = (str(orig_html,'utf-8') + resize_for_databricks)\n",
    "\n",
    "import base64\n",
    "b64 = base64.b64encode(better_html.encode('utf-8'))\n",
    "src = f\"data:text/html;base64,{b64.decode('utf-8')}\"\n",
    "base64d_html = f'<iframe src=\"{src}\" style=\"width:100%; height: 600px\">'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(base64d_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
